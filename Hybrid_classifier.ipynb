{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628be617-a0d6-4b6c-928f-51760adfd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330afb8-ce9a-4e36-b546-14f27a2d465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch \n",
    "from NCF_model.NCF import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588dda43-1977-48a2-a12d-0c813fa92848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCF(\n",
       "  (user_factors): Embedding(610, 50)\n",
       "  (movie_factors): Embedding(9742, 50)\n",
       "  (layers): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.1, inplace=False)\n",
       "    (2): Linear(in_features=100, out_features=30, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv(\"cleaned_100k/ratings.csv\")\n",
    "Movies_df=  pd.read_csv(\"cleaned_100k/descriptions_df.csv\")\n",
    "Movies_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "\n",
    "title = pd.read_csv(\"cleaned_100k/movies.csv\")\n",
    "content_df  =  pd.merge(ratings_df,Movies_df,on='MovieID')\n",
    "content_df.drop(columns=['Timestamp'],inplace=True)\n",
    "#X =  ratings_df.drop(columns=['Rating'])\n",
    "#y = ratings_df['Rating']\n",
    "#content_df  =   pd.read_csv(\"cleaned_100k/content_df.csv\")\n",
    "\n",
    "y_group_user =  content_df.groupby('UserID')\n",
    "y_target_content = []\n",
    "for i,j  in  y_group_user:\n",
    "    y_target_content.append(j['Rating'].values)\n",
    "x_group_user =  content_df.groupby('UserID')\n",
    "#content_df.drop(columns=['Ratings'],inplace=True)\n",
    "x_train_content = []\n",
    "for i,j  in  x_group_user:\n",
    "    x_train_content.append(j.drop(columns='UserID'))\n",
    "    \n",
    "    \n",
    "n_users,n_movies,n_factors =610,9742,50\n",
    "model = NCF(n_users,n_movies,n_factors).to('cuda')\n",
    "model.load_state_dict(torch.load('NCF_model/model.pth', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6dfb0-3aae-4ebb-aced-acd6ec39974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sendh\\AppData\\Local\\Temp\\ipykernel_38560\\1937313586.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Recommender_Response1 = Recommender_Response1.append(new_val, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "new_val = {'Users': 68,'Recommender_Ratings':2}\n",
    "Recommender_Response1 = Recommender_Response1.append(new_val, ignore_index = True)\n",
    "Recommender_Response1.to_csv('Recommender_Responsev1.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf99cb66-3c33-4d0a-9712-0031cbb93839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Users</th>\n",
       "      <th>Recommender_Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Users  Recommender_Ratings\n",
       "0    5.0                  6.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommender_Response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2fff4fe-8d92-49a6-8fbc-c4632d7ff6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mRecommender_Response1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_append\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverify_integrity\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0m_append\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only append a dict if ignore_index=True\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34m\"Can only append a Series if ignore_index=True \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34m\"or if the Series has a name\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mrow_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# infer_objects is needed for\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m#  test_append_empty_frame_to_series_with_dateutil_tz\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mpass\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"append\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\sendh\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\core\\frame.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Recommender_Response1._append??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da80847-f59b-40e3-ae50-b2c0218cbb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d485284-33bc-408b-86ef-e46e56da22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hybrid_Recommender(user_id):\n",
    "    watched = set(x_train_content[user_id]['MovieID'].values)\n",
    "    not_watched = Movies_df[Movies_df['MovieID'].map(lambda x: x not in watched)]\n",
    "    result = pd.DataFrame({'Movie_id':not_watched['MovieID']})\n",
    "    CBF(user_id,not_watched,result)\n",
    "    NCF(user_id,not_watched,result)\n",
    "    result['hybrid_preds'] =  result['collab_preds'] * 0.5 + result['content_preds'] *0.5 \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79d306cf-2ba0-4d96-8586-ec7289eaf38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  CBF(user_id,not_watched,result):\n",
    "    #train  =  [ast.literal_eval(x) for x  in   x_train_content[user_id]['TFIDF']]\n",
    "    train = x_train_content[user_id].iloc[:,2:]\n",
    "    model =  SVR(C=1.3)\n",
    "    model.fit(train,y_target_content[user_id])\n",
    "  \n",
    "    not_watched_tfidf = not_watched.iloc[:,:-1]\n",
    "    preds = model.predict(not_watched_tfidf)\n",
    "    preds =  np.clip(preds,0,5)\n",
    "    result['content_preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0debe90-4b9c-4048-a8d1-e9d3d96b1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NCF(user_id,not_watched,result):\n",
    "    movies = LabelEncoder()\n",
    "    movies.classes_ = np.load('movies.npy')\n",
    "    users = LabelEncoder()\n",
    "    users.classes_ = np.load('users.npy')\n",
    "    x_predict_collab = torch.stack((torch.tensor(users.transform([4]* len(not_watched))),torch.tensor(movies.transform(not_watched['MovieID']))),1).to('cuda')\n",
    "    model.eval()\n",
    "    preds = model(x_predict_collab)\n",
    "    result['collab_preds'] = preds.to('cpu').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47052e7d-4811-4442-a8fb-838127a84af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Top_10_Recommendations(user_id):\n",
    "    result = Hybrid_Recommender(user_id)\n",
    "    movie_ids = result.sort_values('hybrid_preds', ascending=False)['Movie_id'][:10]\n",
    "    movies = list(title[title['MovieID'].isin(movie_ids)]['Title'].values)\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "367bead0-dd2f-4978-aebf-d7497ec311f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similar_movies(name):\n",
    "    cosine_sim = cosine_similarity(Movies_df.iloc[:,:-1],Movies_df.iloc[:,:-1])\n",
    "    idxs = title[title['Title'] == name].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idxs]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    similar = [x  for x,y in sim_scores]\n",
    "    return list(title.iloc[similar]['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56d2be62-6645-40fb-96f5-cf36053569dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Perfect Candidate, A (1996)',\n",
       " 'Cruise, The (1998)',\n",
       " 'Slasher (2004)',\n",
       " \"Darwin's Nightmare (2004)\",\n",
       " 'Connections (1978)',\n",
       " 'All Watched Over by Machines of Loving Grace (2011)',\n",
       " 'Century of the Self, The (2002)',\n",
       " 'The Blue Planet (2001)',\n",
       " 'Planet Earth (2006)',\n",
       " 'Blue Planet II (2017)']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_10_Recommendations(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "547ec3e1-7050-43cb-8c09-6fab56fed404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Raging Bull (1980)',\n",
       " '7th Voyage of Sinbad, The (1958)',\n",
       " 'Woman in the Dunes (Suna no onna) (1964)',\n",
       " \"Man Bites Dog (C'est arrivé près de chez vous) (1992)\",\n",
       " 'Trial, The (Procès, Le) (1962)',\n",
       " 'Come and See (Idi i smotri) (1985)',\n",
       " 'Sword of Doom, The (Dai-bosatsu tôge) (1966)',\n",
       " 'Bittersweet Life, A (Dalkomhan insaeng) (2005)',\n",
       " 'Incendies (2010)',\n",
       " 'Paddington 2 (2017)']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_10_Recommendations(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35bb1b19-7c54-4413-bea2-80a34ead5893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['His Girl Friday (1940)',\n",
       " 'Young Frankenstein (1974)',\n",
       " 'Place in the Sun, A (1951)',\n",
       " 'All That Heaven Allows (1955)',\n",
       " 'Belle époque (1992)',\n",
       " 'Trial, The (Procès, Le) (1962)',\n",
       " 'Eddie Murphy Delirious (1983)',\n",
       " 'Incendies (2010)',\n",
       " 'Everybody Wants Some (2016)',\n",
       " 'Logan (2017)']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_10_Recommendations(444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2da09b36-5426-4432-bf70-5285917d511d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nymphomaniac: Volume II (2013)',\n",
       " 'Passion of the Christ, The (2004)',\n",
       " 'Crouching Tiger, Hidden Dragon (Wo hu cang long) (2000)',\n",
       " 'Infinity (1996)',\n",
       " 'Mr. Holmes (2015)',\n",
       " 'Tristram Shandy: A Cock and Bull Story (2005)',\n",
       " 'Louis C.K.: Hilarious (2010)',\n",
       " 'Wit (2001)',\n",
       " 'No Way Jose (2015)',\n",
       " 'W. (2008)']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Similar_movies('Raging Bull (1980)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "780e4064-c533-43c5-a66a-28bc128ec839",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Hybrid_Recommender(555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6bef2b95-3a84-4752-ab75-e90fd4994788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.521811722104937, 4.293727397918701)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['content_preds'].max(),res['collab_preds'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2978c6e2-8449-4f54-9714-a687f22d66f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3265      4419\n",
       "2011      2677\n",
       "2424      3224\n",
       "2411      3201\n",
       "8241    104283\n",
       "2582      3451\n",
       "7863     93988\n",
       "7602     86781\n",
       "5407     25771\n",
       "6473     52767\n",
       "Name: Movie_id, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hybrid_Recommender(356).sort_values('hybrid_preds', ascending=False)['Movie_id'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "337c57c3-72ff-459a-954d-1de24403714c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Star Wars: Episode IV - A New Hope (1977)',\n",
       " 'Raging Bull (1980)',\n",
       " 'Trust (1990)',\n",
       " 'Manhattan (1979)',\n",
       " 'Manchurian Candidate, The (1962)',\n",
       " 'Woman in the Dunes (Suna no onna) (1964)',\n",
       " 'Dog Soldiers (2002)',\n",
       " 'Bittersweet Life, A (Dalkomhan insaeng) (2005)',\n",
       " 'Raiders of the Lost Ark: The Adaptation (1989)',\n",
       " 'All-Star Superman (2011)']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov = result.sort_values('hybrid_preds', ascending=False)['Movie_id'][:10]\n",
    "list(title[title['MovieID'].isin(mov)]['Title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2906f5dd-a781-4b34-92aa-a8ca4d26eecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_id</th>\n",
       "      <th>content_preds</th>\n",
       "      <th>collab_preds</th>\n",
       "      <th>hybrid_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>1228</td>\n",
       "      <td>4.085381</td>\n",
       "      <td>4.187244</td>\n",
       "      <td>6.229934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>69524</td>\n",
       "      <td>4.529487</td>\n",
       "      <td>3.883759</td>\n",
       "      <td>6.148503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>1236</td>\n",
       "      <td>3.788333</td>\n",
       "      <td>4.215914</td>\n",
       "      <td>6.110080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>3224</td>\n",
       "      <td>3.664027</td>\n",
       "      <td>4.266088</td>\n",
       "      <td>6.098102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>5833</td>\n",
       "      <td>3.837443</td>\n",
       "      <td>4.176753</td>\n",
       "      <td>6.095474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>2799</td>\n",
       "      <td>3.492524</td>\n",
       "      <td>1.550392</td>\n",
       "      <td>3.296654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>3973</td>\n",
       "      <td>3.495651</td>\n",
       "      <td>1.525869</td>\n",
       "      <td>3.273694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>3774</td>\n",
       "      <td>3.517409</td>\n",
       "      <td>1.509495</td>\n",
       "      <td>3.268199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180</th>\n",
       "      <td>8387</td>\n",
       "      <td>3.327863</td>\n",
       "      <td>1.581333</td>\n",
       "      <td>3.245265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>5323</td>\n",
       "      <td>3.189718</td>\n",
       "      <td>1.504746</td>\n",
       "      <td>3.099605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9656 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Movie_id  content_preds  collab_preds  hybrid_preds\n",
       "929       1228       4.085381      4.187244      6.229934\n",
       "7063     69524       4.529487      3.883759      6.148503\n",
       "936       1236       3.788333      4.215914      6.110080\n",
       "2424      3224       3.664027      4.266088      6.098102\n",
       "4083      5833       3.837443      4.176753      6.095474\n",
       "...        ...            ...           ...           ...\n",
       "2105      2799       3.492524      1.550392      3.296654\n",
       "2964      3973       3.495651      1.525869      3.273694\n",
       "2825      3774       3.517409      1.509495      3.268199\n",
       "5180      8387       3.327863      1.581333      3.245265\n",
       "3804      5323       3.189718      1.504746      3.099605\n",
       "\n",
       "[9656 rows x 4 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values('hybrid_preds', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0bc965-3106-45ab-9ddc-bd2a9134b603",
   "metadata": {},
   "source": [
    "# Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cb5db5c-8e63-47a9-8fde-15d874c8d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recommender_Response1 = pd.read_csv('Recommender_Responsev1.csv',usecols=['Users','Recommender_Ratings'])  \n",
    "Recommender_Response2 = pd.read_csv('Recommender_Responsev2.csv',usecols=['Users','Recommender_Ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c472087a-0b90-4c0a-8dba-7efc2760b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c491a3b-1987-4b6d-aac1-9ce6d935a111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.1346845820953142, pvalue=0.8941438046418504)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(Recommender_Response1['Recommender_Ratings'].values,Recommender_Response2['Recommender_Ratings'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48a9f3ca-a7c8-443f-a6a7-2abb559c786d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-6.984538909891173, pvalue=0.999981072080732)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind([1,2,1,0,1,2],[5,4,5,3,4,5],alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2fc10ae-bbbf-456b-8716-c231baa4c9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mttest_ind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mequal_var\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnan_policy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'propagate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpermutations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0malternative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'two-sided'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Calculate the T-test for the means of *two independent* samples of scores.\n",
       "\n",
       "This is a test for the null hypothesis that 2 independent samples\n",
       "have identical average (expected) values. This test assumes that the\n",
       "populations have identical variances by default.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a, b : array_like\n",
       "    The arrays must have the same shape, except in the dimension\n",
       "    corresponding to `axis` (the first, by default).\n",
       "axis : int or None, optional\n",
       "    Axis along which to compute test. If None, compute over the whole\n",
       "    arrays, `a`, and `b`.\n",
       "equal_var : bool, optional\n",
       "    If True (default), perform a standard independent 2 sample test\n",
       "    that assumes equal population variances [1]_.\n",
       "    If False, perform Welch's t-test, which does not assume equal\n",
       "    population variance [2]_.\n",
       "\n",
       "    .. versionadded:: 0.11.0\n",
       "\n",
       "nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
       "    Defines how to handle when input contains nan.\n",
       "    The following options are available (default is 'propagate'):\n",
       "\n",
       "      * 'propagate': returns nan\n",
       "      * 'raise': throws an error\n",
       "      * 'omit': performs the calculations ignoring nan values\n",
       "\n",
       "    The 'omit' option is not currently available for permutation tests or\n",
       "    one-sided asympyotic tests.\n",
       "\n",
       "permutations : non-negative int, np.inf, or None (default), optional\n",
       "    If 0 or None (default), use the t-distribution to calculate p-values.\n",
       "    Otherwise, `permutations` is  the number of random permutations that\n",
       "    will be used to estimate p-values using a permutation test. If\n",
       "    `permutations` equals or exceeds the number of distinct partitions of\n",
       "    the pooled data, an exact test is performed instead (i.e. each\n",
       "    distinct partition is used exactly once). See Notes for details.\n",
       "\n",
       "    .. versionadded:: 1.7.0\n",
       "\n",
       "random_state : {None, int, `numpy.random.Generator`,\n",
       "        `numpy.random.RandomState`}, optional\n",
       "\n",
       "    If `seed` is None (or `np.random`), the `numpy.random.RandomState`\n",
       "    singleton is used.\n",
       "    If `seed` is an int, a new ``RandomState`` instance is used,\n",
       "    seeded with `seed`.\n",
       "    If `seed` is already a ``Generator`` or ``RandomState`` instance then\n",
       "    that instance is used.\n",
       "\n",
       "    Pseudorandom number generator state used to generate permutations\n",
       "    (used only when `permutations` is not None).\n",
       "\n",
       "    .. versionadded:: 1.7.0\n",
       "\n",
       "alternative : {'two-sided', 'less', 'greater'}, optional\n",
       "    Defines the alternative hypothesis.\n",
       "    The following options are available (default is 'two-sided'):\n",
       "\n",
       "    * 'two-sided': the means of the distributions underlying the samples\n",
       "      are unequal.\n",
       "    * 'less': the mean of the distribution underlying the first sample\n",
       "      is less than the mean of the distribution underlying the second\n",
       "      sample.\n",
       "    * 'greater': the mean of the distribution underlying the first\n",
       "      sample is greater than the mean of the distribution underlying\n",
       "      the second sample.\n",
       "\n",
       "    .. versionadded:: 1.6.0\n",
       "\n",
       "trim : float, optional\n",
       "    If nonzero, performs a trimmed (Yuen's) t-test.\n",
       "    Defines the fraction of elements to be trimmed from each end of the\n",
       "    input samples. If 0 (default), no elements will be trimmed from either\n",
       "    side. The number of trimmed elements from each tail is the floor of the\n",
       "    trim times the number of elements. Valid range is [0, .5).\n",
       "\n",
       "    .. versionadded:: 1.7\n",
       "\n",
       "Returns\n",
       "-------\n",
       "statistic : float or array\n",
       "    The calculated t-statistic.\n",
       "pvalue : float or array\n",
       "    The p-value.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Suppose we observe two independent samples, e.g. flower petal lengths, and\n",
       "we are considering whether the two samples were drawn from the same\n",
       "population (e.g. the same species of flower or two species with similar\n",
       "petal characteristics) or two different populations.\n",
       "\n",
       "The t-test quantifies the difference between the arithmetic means\n",
       "of the two samples. The p-value quantifies the probability of observing\n",
       "as or more extreme values assuming the null hypothesis, that the\n",
       "samples are drawn from populations with the same population means, is true.\n",
       "A p-value larger than a chosen threshold (e.g. 5% or 1%) indicates that\n",
       "our observation is not so unlikely to have occurred by chance. Therefore,\n",
       "we do not reject the null hypothesis of equal population means.\n",
       "If the p-value is smaller than our threshold, then we have evidence\n",
       "against the null hypothesis of equal population means.\n",
       "\n",
       "By default, the p-value is determined by comparing the t-statistic of the\n",
       "observed data against a theoretical t-distribution.\n",
       "When ``1 < permutations < binom(n, k)``, where\n",
       "\n",
       "* ``k`` is the number of observations in `a`,\n",
       "* ``n`` is the total number of observations in `a` and `b`, and\n",
       "* ``binom(n, k)`` is the binomial coefficient (``n`` choose ``k``),\n",
       "\n",
       "the data are pooled (concatenated), randomly assigned to either group `a`\n",
       "or `b`, and the t-statistic is calculated. This process is performed\n",
       "repeatedly (`permutation` times), generating a distribution of the\n",
       "t-statistic under the null hypothesis, and the t-statistic of the observed\n",
       "data is compared to this distribution to determine the p-value.\n",
       "Specifically, the p-value reported is the \"achieved significance level\"\n",
       "(ASL) as defined in 4.4 of [3]_. Note that there are other ways of\n",
       "estimating p-values using randomized permutation tests; for other\n",
       "options, see the more general `permutation_test`.\n",
       "\n",
       "When ``permutations >= binom(n, k)``, an exact test is performed: the data\n",
       "are partitioned between the groups in each distinct way exactly once.\n",
       "\n",
       "The permutation test can be computationally expensive and not necessarily\n",
       "more accurate than the analytical test, but it does not make strong\n",
       "assumptions about the shape of the underlying distribution.\n",
       "\n",
       "Use of trimming is commonly referred to as the trimmed t-test. At times\n",
       "called Yuen's t-test, this is an extension of Welch's t-test, with the\n",
       "difference being the use of winsorized means in calculation of the variance\n",
       "and the trimmed sample size in calculation of the statistic. Trimming is\n",
       "recommended if the underlying distribution is long-tailed or contaminated\n",
       "with outliers [4]_.\n",
       "\n",
       "The statistic is calculated as ``(np.mean(a) - np.mean(b))/se``, where\n",
       "``se`` is the standard error. Therefore, the statistic will be positive\n",
       "when the sample mean of `a` is greater than the sample mean of `b` and\n",
       "negative when the sample mean of `a` is less than the sample mean of\n",
       "`b`.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test\n",
       "\n",
       ".. [2] https://en.wikipedia.org/wiki/Welch%27s_t-test\n",
       "\n",
       ".. [3] B. Efron and T. Hastie. Computer Age Statistical Inference. (2016).\n",
       "\n",
       ".. [4] Yuen, Karen K. \"The Two-Sample Trimmed t for Unequal Population\n",
       "       Variances.\" Biometrika, vol. 61, no. 1, 1974, pp. 165-170. JSTOR,\n",
       "       www.jstor.org/stable/2334299. Accessed 30 Mar. 2021.\n",
       "\n",
       ".. [5] Yuen, Karen K., and W. J. Dixon. \"The Approximate Behaviour and\n",
       "       Performance of the Two-Sample Trimmed t.\" Biometrika, vol. 60,\n",
       "       no. 2, 1973, pp. 369-374. JSTOR, www.jstor.org/stable/2334550.\n",
       "       Accessed 30 Mar. 2021.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from scipy import stats\n",
       ">>> rng = np.random.default_rng()\n",
       "\n",
       "Test with sample with identical means:\n",
       "\n",
       ">>> rvs1 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)\n",
       ">>> rvs2 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)\n",
       ">>> stats.ttest_ind(rvs1, rvs2)\n",
       "Ttest_indResult(statistic=-0.4390847099199348, pvalue=0.6606952038870015)\n",
       ">>> stats.ttest_ind(rvs1, rvs2, equal_var=False)\n",
       "Ttest_indResult(statistic=-0.4390847099199348, pvalue=0.6606952553131064)\n",
       "\n",
       "`ttest_ind` underestimates p for unequal variances:\n",
       "\n",
       ">>> rvs3 = stats.norm.rvs(loc=5, scale=20, size=500, random_state=rng)\n",
       ">>> stats.ttest_ind(rvs1, rvs3)\n",
       "Ttest_indResult(statistic=-1.6370984482905417, pvalue=0.1019251574705033)\n",
       ">>> stats.ttest_ind(rvs1, rvs3, equal_var=False)\n",
       "Ttest_indResult(statistic=-1.637098448290542, pvalue=0.10202110497954867)\n",
       "\n",
       "When ``n1 != n2``, the equal variance t-statistic is no longer equal to the\n",
       "unequal variance t-statistic:\n",
       "\n",
       ">>> rvs4 = stats.norm.rvs(loc=5, scale=20, size=100, random_state=rng)\n",
       ">>> stats.ttest_ind(rvs1, rvs4)\n",
       "Ttest_indResult(statistic=-1.9481646859513422, pvalue=0.05186270935842703)\n",
       ">>> stats.ttest_ind(rvs1, rvs4, equal_var=False)\n",
       "Ttest_indResult(statistic=-1.3146566100751664, pvalue=0.1913495266513811)\n",
       "\n",
       "T-test with different means, variance, and n:\n",
       "\n",
       ">>> rvs5 = stats.norm.rvs(loc=8, scale=20, size=100, random_state=rng)\n",
       ">>> stats.ttest_ind(rvs1, rvs5)\n",
       "Ttest_indResult(statistic=-2.8415950600298774, pvalue=0.0046418707568707885)\n",
       ">>> stats.ttest_ind(rvs1, rvs5, equal_var=False)\n",
       "Ttest_indResult(statistic=-1.8686598649188084, pvalue=0.06434714193919686)\n",
       "\n",
       "When performing a permutation test, more permutations typically yields\n",
       "more accurate results. Use a ``np.random.Generator`` to ensure\n",
       "reproducibility:\n",
       "\n",
       ">>> stats.ttest_ind(rvs1, rvs5, permutations=10000,\n",
       "...                 random_state=rng)\n",
       "Ttest_indResult(statistic=-2.8415950600298774, pvalue=0.0052994700529947)\n",
       "\n",
       "Take these two samples, one of which has an extreme tail.\n",
       "\n",
       ">>> a = (56, 128.6, 12, 123.8, 64.34, 78, 763.3)\n",
       ">>> b = (1.1, 2.9, 4.2)\n",
       "\n",
       "Use the `trim` keyword to perform a trimmed (Yuen) t-test. For example,\n",
       "using 20% trimming, ``trim=.2``, the test will reduce the impact of one\n",
       "(``np.floor(trim*len(a))``) element from each tail of sample `a`. It will\n",
       "have no effect on sample `b` because ``np.floor(trim*len(b))`` is 0.\n",
       "\n",
       ">>> stats.ttest_ind(a, b, trim=.2)\n",
       "Ttest_indResult(statistic=3.4463884028073513,\n",
       "                pvalue=0.01369338726499547)\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\sendh\\anaconda3\\envs\\deep\\lib\\site-packages\\scipy\\stats\\_stats_py.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ttest_ind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b91db8b-1490-4ac0-926f-e129984f9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Recommender_Response1 = pd.DataFrame({'Users':[],'Recommender_Ratings':[]})\n",
    "Recommender_Response2 = pd.DataFrame({'Users':[],'Recommender_Ratings':[]})\n",
    "                    \n",
    "Recommender_Response1.to_csv('Recommender_Responsev1.csv') \n",
    "                                                         \n",
    "Recommender_Response2.to_csv('Recommender_Responsev2.csv')     \n",
    "\n",
    "new_val = {'Users': 68,'Recommender_Ratings':2}\n",
    "Recommender_Response1 = Recommender_Response1.append(new_val, ignore_index = True)\n",
    "Recommender_Response1.to_csv('Recommender_Responsev1.csv') \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4715e389-c04a-4d98-b3c3-d899a2ad9279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ff43383-cae8-49a3-bc10-10e4a3a6e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(Movies_df.iloc[:,:-1],Movies_df.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "46f68849-ae89-474b-921b-76c67f13ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = title[title['Title'] == 'Toy Story (1995)'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1d8baa07-f4b5-48a5-925b-80c9c0a37e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = list(enumerate(cosine_sim[idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "86a36e97-deaf-4844-af2d-234e74608895",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "sim_scores = sim_scores[1:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "479cd1d2-8bf4-4819-b85b-053df135c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = [x  for x,y in sim_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "01a3fb3f-c56f-480f-ac76-014e59257dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar = list(np.argsort(cosine_sim[idxs])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "307dc5f6-5356-4a0b-8ca2-d6cc573c44b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Bug's Life, A (1998)\",\n",
       " 'Turbo (2013)',\n",
       " 'Toy Story 2 (1999)',\n",
       " 'Monsters, Inc. (2001)',\n",
       " 'Antz (1998)',\n",
       " 'The Lego Movie (2014)',\n",
       " 'Shrek (2001)',\n",
       " 'Asterix and the Vikings (Astérix et les Vikings) (2006)',\n",
       " 'Gnomeo & Juliet (2011)',\n",
       " 'Moana (2016)',\n",
       " 'Over the Hedge (2006)',\n",
       " 'Space Jam (1996)',\n",
       " 'Happy Feet (2006)',\n",
       " 'Paddington 2 (2017)',\n",
       " 'Rio 2 (2014)',\n",
       " 'Ant Bully, The (2006)',\n",
       " 'Puss in Boots (Nagagutsu o haita neko) (1969)',\n",
       " 'The Good Dinosaur (2015)',\n",
       " 'Karlson Returns (1970)',\n",
       " \"Porky's Hare Hunt (1938)\"]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(title.iloc[similar]['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b87f414-1ec2-4f1d-bb21-74f916b9e2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9737"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Movies_df[Movies_df['MovieID'] == 193581].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c75f0a-7222-4060-adce-095d0270096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = LabelEncoder()\n",
    "movies.classes_ = np.load('movies.npy')\n",
    "users = LabelEncoder()\n",
    "users.classes_ = np.load('users.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9b96def-784a-429f-ac62-d71c3c48fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id =77\n",
    "watched = set(x_train_content[user_id]['MovieID'].values)\n",
    "not_watched = Movies_df[Movies_df['MovieID'].map(lambda x: x not in watched)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26904127-f47d-458f-adda-bf793a27779c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44cbe6a9-2f9b-46e8-a2f1-743f531255b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict_collab = torch.stack((torch.tensor(users.transform([4]* len(not_watched))),torch.tensor(movies.transform(not_watched['MovieID']))),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55e58eae-cc18-4b07-a1a3-7f43e6524057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCF(\n",
       "  (user_factors): Embedding(610, 50)\n",
       "  (movie_factors): Embedding(9742, 50)\n",
       "  (layers): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.1, inplace=False)\n",
       "    (2): Linear(in_features=100, out_features=30, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users,n_movies,n_factors =610,9742,50\n",
    "model = NCF(n_users,n_movies,n_factors)\n",
    "model.load_state_dict(torch.load('NCF_model/model.pth', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb804809-a097-4c17-82c3-1cba578fb8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
