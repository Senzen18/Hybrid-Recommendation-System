# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/MLP.ipynb.

# %% auto 0
__all__ = ['path_data', 'path_gz', 'accuracy', 'report', 'Dataset', 'fit', 'get_dls']

# %% ../nbs/MLP.ipynb 2
import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl, numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from torch import tensor
from fastcore.test import test_close
torch.manual_seed(42)
path_data = Path("MNIST")
path_data.mkdir(exist_ok=True)
path_gz = path_data/'mnist.pkl.gz'
from .core import *

# %% ../nbs/MLP.ipynb 63
def accuracy(preds,targ):
    return (preds.argmax(1) == targ).float().mean()
    
    

# %% ../nbs/MLP.ipynb 64
def report(loss, preds, yb): print(f'{loss:.2f}, {accuracy(preds, yb):.2f}')

# %% ../nbs/MLP.ipynb 76
class Dataset():
    def __init__(self,x,y): self.x,self.y = x,y
    def __len__(self): return len(self.x)
    def __getitem__(self,i): return self.x[i],self.y[i]

# %% ../nbs/MLP.ipynb 92
from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler

# %% ../nbs/MLP.ipynb 94
def fit(epochs, model, loss_func, opt, train_dl, valid_dl):
    for epoch in range(epochs):
        model.train()
        for xb,yb in train_dl:
            loss = loss_func(model(xb), yb)
            loss.backward()
            opt.step()
            opt.zero_grad()

        model.eval()
        with torch.no_grad():
            tot_loss,tot_acc,count = 0.,0.,0
            for xb,yb in valid_dl:
                pred = model(xb)
                n = len(xb)
                count += n
                tot_loss += loss_func(pred,yb).item()*n
                tot_acc  += accuracy (pred,yb).item()*n
        print(epoch, tot_loss/count, tot_acc/count)
    return tot_loss/count, tot_acc/count
     

# %% ../nbs/MLP.ipynb 95
def get_dls(train_ds, valid_ds, bs,collate=False,**kwargs):
    if collate: 
         return (DataLoader(train_ds, batch_size=bs, shuffle=True,collate_fn = collate_dict(train_ds), **kwargs),
            DataLoader(valid_ds, batch_size=bs*2,collate_fn = collate_dict(valid_ds), **kwargs))
        
    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),
            DataLoader(valid_ds, batch_size=bs*2,**kwargs))
     
